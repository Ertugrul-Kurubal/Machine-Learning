{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "43a9cd95aa030499ef934e4da31e07dde54f3fc3a1fd0cc4aeef7f16459ee2ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Grid Search \n",
    "\n",
    "We can search through a variety of combinations of hyperparameters with a grid search. While many linear models are quite simple and even come with their own specialized versions that do a search for you, this method of a grid search will can be applied to *any* model from sklearn, and we will need to use it later on for more complex models, such as Support Vector Machines."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TV</th>\n      <th>radio</th>\n      <th>newspaper</th>\n      <th>sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>230.1</td>\n      <td>37.8</td>\n      <td>69.2</td>\n      <td>22.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44.5</td>\n      <td>39.3</td>\n      <td>45.1</td>\n      <td>10.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17.2</td>\n      <td>45.9</td>\n      <td>69.3</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>151.5</td>\n      <td>41.3</td>\n      <td>58.5</td>\n      <td>18.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180.8</td>\n      <td>10.8</td>\n      <td>58.4</td>\n      <td>12.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "### Formatting Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE X and y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "### Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class ElasticNet in module sklearn.linear_model._coordinate_descent:\n\nclass ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n |  \n |  Linear regression with combined L1 and L2 priors as regularizer.\n |  \n |  Minimizes the objective function::\n |  \n |          1 / (2 * n_samples) * ||y - Xw||^2_2\n |          + alpha * l1_ratio * ||w||_1\n |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n |  \n |  If you are interested in controlling the L1 and L2 penalty\n |  separately, keep in mind that this is equivalent to::\n |  \n |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n |  \n |  where::\n |  \n |          alpha = a + b and l1_ratio = a / (a + b)\n |  \n |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n |  unless you supply your own sequence of alpha.\n |  \n |  Read more in the :ref:`User Guide <elastic_net>`.\n |  \n |  Parameters\n |  ----------\n |  alpha : float, default=1.0\n |      Constant that multiplies the penalty terms. Defaults to 1.0.\n |      See the notes for the exact mathematical meaning of this\n |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n |      solved by the :class:`LinearRegression` object. For numerical\n |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n |      Given this, you should use the :class:`LinearRegression` object.\n |  \n |  l1_ratio : float, default=0.5\n |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n |      combination of L1 and L2.\n |  \n |  fit_intercept : bool, default=True\n |      Whether the intercept should be estimated or not. If ``False``, the\n |      data is assumed to be already centered.\n |  \n |  normalize : bool, default=False\n |      This parameter is ignored when ``fit_intercept`` is set to False.\n |      If True, the regressors X will be normalized before regression by\n |      subtracting the mean and dividing by the l2-norm.\n |      If you wish to standardize, please use\n |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n |      on an estimator with ``normalize=False``.\n |  \n |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n |      Whether to use a precomputed Gram matrix to speed up\n |      calculations. The Gram matrix can also be passed as argument.\n |      For sparse input this option is always ``False`` to preserve sparsity.\n |  \n |  max_iter : int, default=1000\n |      The maximum number of iterations.\n |  \n |  copy_X : bool, default=True\n |      If ``True``, X will be copied; else, it may be overwritten.\n |  \n |  tol : float, default=1e-4\n |      The tolerance for the optimization: if the updates are\n |      smaller than ``tol``, the optimization code checks the\n |      dual gap for optimality and continues until it is smaller\n |      than ``tol``.\n |  \n |  warm_start : bool, default=False\n |      When set to ``True``, reuse the solution of the previous call to fit as\n |      initialization, otherwise, just erase the previous solution.\n |      See :term:`the Glossary <warm_start>`.\n |  \n |  positive : bool, default=False\n |      When set to ``True``, forces the coefficients to be positive.\n |  \n |  random_state : int, RandomState instance, default=None\n |      The seed of the pseudo random number generator that selects a random\n |      feature to update. Used when ``selection`` == 'random'.\n |      Pass an int for reproducible output across multiple function calls.\n |      See :term:`Glossary <random_state>`.\n |  \n |  selection : {'cyclic', 'random'}, default='cyclic'\n |      If set to 'random', a random coefficient is updated every iteration\n |      rather than looping over features sequentially by default. This\n |      (setting to 'random') often leads to significantly faster convergence\n |      especially when tol is higher than 1e-4.\n |  \n |  Attributes\n |  ----------\n |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n |      Parameter vector (w in the cost function formula).\n |  \n |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_tasks, n_features)\n |      Sparse representation of the `coef_`.\n |  \n |  intercept_ : float or ndarray of shape (n_targets,)\n |      Independent term in decision function.\n |  \n |  n_iter_ : list of int\n |      Number of iterations run by the coordinate descent solver to reach\n |      the specified tolerance.\n |  \n |  dual_gap_ : float or ndarray of shape (n_targets,)\n |      Given param alpha, the dual gaps at the end of the optimization,\n |      same shape as each observation of y.\n |  \n |  Examples\n |  --------\n |  >>> from sklearn.linear_model import ElasticNet\n |  >>> from sklearn.datasets import make_regression\n |  \n |  >>> X, y = make_regression(n_features=2, random_state=0)\n |  >>> regr = ElasticNet(random_state=0)\n |  >>> regr.fit(X, y)\n |  ElasticNet(random_state=0)\n |  >>> print(regr.coef_)\n |  [18.83816048 64.55968825]\n |  >>> print(regr.intercept_)\n |  1.451...\n |  >>> print(regr.predict([[0, 0]]))\n |  [1.451...]\n |  \n |  \n |  Notes\n |  -----\n |  To avoid unnecessary memory duplication the X argument of the fit method\n |  should be directly passed as a Fortran-contiguous numpy array.\n |  \n |  See Also\n |  --------\n |  ElasticNetCV : Elastic net model with best model selection by\n |      cross-validation.\n |  SGDRegressor : Implements elastic net regression with incremental training.\n |  SGDClassifier : Implements logistic regression with elastic net penalty\n |      (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n |  \n |  Method resolution order:\n |      ElasticNet\n |      sklearn.base.MultiOutputMixin\n |      sklearn.base.RegressorMixin\n |      sklearn.linear_model._base.LinearModel\n |      sklearn.base.BaseEstimator\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y, sample_weight=None, check_input=True)\n |      Fit model with coordinate descent.\n |      \n |      Parameters\n |      ----------\n |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n |          Data.\n |      \n |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n |          Target. Will be cast to X's dtype if necessary.\n |      \n |      sample_weight : float or array-like of shape (n_samples,), default=None\n |          Sample weight.\n |      \n |          .. versionadded:: 0.23\n |      \n |      check_input : bool, default=True\n |          Allow to bypass several input checking.\n |          Don't use this parameter unless you know what you do.\n |      \n |      Notes\n |      -----\n |      \n |      Coordinate descent is an algorithm that considers each column of\n |      data at a time hence it will automatically convert the X input\n |      as a Fortran-contiguous numpy array if necessary.\n |      \n |      To avoid memory re-allocation it is advised to allocate the\n |      initial data in memory directly using that format.\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n |      Compute elastic net path with coordinate descent.\n |      \n |      The elastic net optimization function varies for mono and multi-outputs.\n |      \n |      For mono-output tasks it is::\n |      \n |          1 / (2 * n_samples) * ||y - Xw||^2_2\n |          + alpha * l1_ratio * ||w||_1\n |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n |      \n |      For multi-output tasks it is::\n |      \n |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n |          + alpha * l1_ratio * ||W||_21\n |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n |      \n |      Where::\n |      \n |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n |      \n |      i.e. the sum of norm of each row.\n |      \n |      Read more in the :ref:`User Guide <elastic_net>`.\n |      \n |      Parameters\n |      ----------\n |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n |          Training data. Pass directly as Fortran-contiguous data to avoid\n |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n |          can be sparse.\n |      \n |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_outputs)\n |          Target values.\n |      \n |      l1_ratio : float, default=0.5\n |          Number between 0 and 1 passed to elastic net (scaling between\n |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n |      \n |      eps : float, default=1e-3\n |          Length of the path. ``eps=1e-3`` means that\n |          ``alpha_min / alpha_max = 1e-3``.\n |      \n |      n_alphas : int, default=100\n |          Number of alphas along the regularization path.\n |      \n |      alphas : ndarray, default=None\n |          List of alphas where to compute the models.\n |          If None alphas are set automatically.\n |      \n |      precompute : 'auto', bool or array-like of shape (n_features, n_features),                 default='auto'\n |          Whether to use a precomputed Gram matrix to speed up\n |          calculations. If set to ``'auto'`` let us decide. The Gram\n |          matrix can also be passed as argument.\n |      \n |      Xy : array-like of shape (n_features,) or (n_features, n_outputs),         default=None\n |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n |          only when the Gram matrix is precomputed.\n |      \n |      copy_X : bool, default=True\n |          If ``True``, X will be copied; else, it may be overwritten.\n |      \n |      coef_init : ndarray of shape (n_features, ), default=None\n |          The initial values of the coefficients.\n |      \n |      verbose : bool or int, default=False\n |          Amount of verbosity.\n |      \n |      return_n_iter : bool, default=False\n |          Whether to return the number of iterations or not.\n |      \n |      positive : bool, default=False\n |          If set to True, forces coefficients to be positive.\n |          (Only allowed when ``y.ndim == 1``).\n |      \n |      check_input : bool, default=True\n |          If set to False, the input validation checks are skipped (including the\n |          Gram matrix when provided). It is assumed that they are handled\n |          by the caller.\n |      \n |      **params : kwargs\n |          Keyword arguments passed to the coordinate descent solver.\n |      \n |      Returns\n |      -------\n |      alphas : ndarray of shape (n_alphas,)\n |          The alphas along the path where models are computed.\n |      \n |      coefs : ndarray of shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)\n |          Coefficients along the path.\n |      \n |      dual_gaps : ndarray of shape (n_alphas,)\n |          The dual gaps at the end of the optimization for each alpha.\n |      \n |      n_iters : list of int\n |          The number of iterations taken by the coordinate descent optimizer to\n |          reach the specified tolerance for each alpha.\n |          (Is returned when ``return_n_iter`` is set to True).\n |      \n |      See Also\n |      --------\n |      MultiTaskElasticNet\n |      MultiTaskElasticNetCV\n |      ElasticNet\n |      ElasticNetCV\n |      \n |      Notes\n |      -----\n |      For an example, see\n |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  sparse_coef_\n |      Sparse representation of the fitted `coef_`.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.RegressorMixin:\n |  \n |  score(self, X, y, sample_weight=None)\n |      Return the coefficient of determination :math:`R^2` of the\n |      prediction.\n |      \n |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n |      can be negative (because the model can be arbitrarily worse). A\n |      constant model that always predicts the expected value of `y`,\n |      disregarding the input features, would get a :math:`R^2` score of\n |      0.0.\n |      \n |      Parameters\n |      ----------\n |      X : array-like of shape (n_samples, n_features)\n |          Test samples. For some estimators this may be a precomputed\n |          kernel matrix or a list of generic objects instead with shape\n |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n |          is the number of samples used in the fitting for the estimator.\n |      \n |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n |          True values for `X`.\n |      \n |      sample_weight : array-like of shape (n_samples,), default=None\n |          Sample weights.\n |      \n |      Returns\n |      -------\n |      score : float\n |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n |      \n |      Notes\n |      -----\n |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n |      with default value of :func:`~sklearn.metrics.r2_score`.\n |      This influences the ``score`` method of all the multioutput\n |      regressors (except for\n |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.linear_model._base.LinearModel:\n |  \n |  predict(self, X)\n |      Predict using the linear model.\n |      \n |      Parameters\n |      ----------\n |      X : array-like or sparse matrix, shape (n_samples, n_features)\n |          Samples.\n |      \n |      Returns\n |      -------\n |      C : array, shape (n_samples,)\n |          Returns predicted values.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __getstate__(self)\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : dict\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n |      parameters of the form ``<component>__<parameter>`` so that it's\n |      possible to update each component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : estimator instance\n |          Estimator instance.\n\n"
     ]
    }
   ],
   "source": [
    "help(ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_model = ElasticNet()"
   ]
  },
  {
   "source": [
    "### Grid Search\n",
    "\n",
    "A search consists of:\n",
    "\n",
    "* an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
    "* a parameter space;\n",
    "* a method for searching or sampling candidates;\n",
    "* a cross-validation scheme \n",
    "* a score function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,1,5,10,50,100],\n",
    "              'l1_ratio':[.1, .5, .7, .9, .95, .99, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose number a personal preference\n",
    "grid_model = GridSearchCV(estimator=base_elastic_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=5,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "source": [
    "### Using Best Model From Grid Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.387342642087474"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}